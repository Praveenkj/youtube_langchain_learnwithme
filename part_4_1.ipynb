{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb9b529",
   "metadata": {},
   "source": [
    "### Part 4 - Output Parsers\n",
    "LangChain output parsers turn raw LLM text into structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "760abbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "google_llm = ChatGoogleGenerativeAI(\n",
    "    temperature=0,\n",
    "    model=\"gemini-2.0-flash\", \n",
    "    api_key=google_api_key,\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "openai_llm = ChatOpenAI(\n",
    "    temperature=0, \n",
    "    model=\"gpt-4\", \n",
    "    api_key=openai_api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fec9005",
   "metadata": {},
   "source": [
    "##### String output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "474c0a14",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[164], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m google_llm \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[1;32m      9\u001b[0m res \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcelebrity_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElon Musk\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Give me a brief info in 1 line about this celebrity: {celebrity_name}\",\n",
    ")\n",
    "\n",
    "chain = prompt | google_llm | StrOutputParser()\n",
    "\n",
    "res = chain.invoke({\"celebrity_name\": \"Elon Musk\"})\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e336dc2",
   "metadata": {},
   "source": [
    "##### Json output parser - Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b26dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial variables\n",
    "\n",
    "template = PromptTemplate.from_template(\n",
    "    \"Hello {name}, today is {date}\"\n",
    "    partial_variables={\"date\": \"2025-09-07\"},  # Pre-filled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff16a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Donald John Trump', 'age': 77, 'country': 'United States of America'}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Give me info about this celebrity: {celebrity_name}. I want name, age and country.\n",
    "    \\n{format_instructions}\"\"\",\n",
    "    partial_variables={\"format_instructions\":json_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | google_llm | json_parser\n",
    "\n",
    "chain.invoke({\"celebrity_name\": \"Trump\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c647d12e",
   "metadata": {},
   "source": [
    "##### Json output parser - Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d8da59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class BirthInfo(BaseModel):\n",
    "    birth_date: str = Field(description=\"Date of birth of the person\")\n",
    "    place_of_birth: str = Field(description=\"Place of birth\")\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"Name of the person\")\n",
    "    age: str = Field(description=\"Age of the person\")\n",
    "    birth_info: BirthInfo = Field(description=\"Birth information\")\n",
    "    \n",
    "\n",
    "json_parser = JsonOutputParser(pydantic_object=Person)\n",
    "\n",
    "json_parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Give me info about this celebrity: {celebrity_name}\\n{format_instructions}\",\n",
    "    partial_variables={\"format_instructions\":json_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | google_llm | json_parser\n",
    "\n",
    "chain.invoke({\"celebrity_name\": \"Elon Musk\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915acfb3",
   "metadata": {},
   "source": [
    "##### Pydantic output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "61bf66a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Elon Musk', age='52', birth_date='June 28, 1971', place_of_birth='Pretoria, South Africa')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"Name of the person\")\n",
    "    age: str = Field(description=\"Age of the person\")\n",
    "    birth_date: str = Field(description=\"Date of birth of the person\")\n",
    "    place_of_birth: str = Field(description=\"Place of birth\")\n",
    "\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=Person)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Give me info about this celebrity: {celebrity_name}\\n{format_instructions}\",\n",
    "    partial_variables={\"format_instructions\":pydantic_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | google_llm | pydantic_parser\n",
    "\n",
    "chain.invoke({\"celebrity_name\": \"Elon Musk\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7d33b7",
   "metadata": {},
   "source": [
    "##### Structured output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6934e4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Elon Musk', 'age': '52', 'birth_date': '28/06/1971'}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"name\", description=\"name of the person\"),\n",
    "    ResponseSchema(name=\"age\", description=\"age of the person\"),\n",
    "    ResponseSchema(name=\"birth_date\", description=\"birth date of the person\")\n",
    "]\n",
    "\n",
    "structured_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# structured_parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "\"\"\"Give me name, age and date of birth in dd/mm/yyyy format for this celebrity: {celebrity_name}\n",
    "\\n {format_instructions}\"\"\",\n",
    "partial_variables={\"format_instructions\":structured_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# prompt.format(celebrity_name=\"Elon Musk\")\n",
    "\n",
    "chain = prompt | google_llm | structured_parser\n",
    "\n",
    "chain.invoke({\"celebrity_name\": \"Elon Musk\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e10917e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91b4fad5",
   "metadata": {},
   "source": [
    "##### CSV list output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ec493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elon Musk', '52', '28/06/1971']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "csv_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "\"\"\"Give me name, age and date of birth in dd/mm/yyyy format for this celebrity: {celebrity_name}\n",
    "\\n {format_instructions}\"\"\",\n",
    "partial_variables={\"format_instructions\":csv_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | google_llm | csv_parser\n",
    "\n",
    "chain.invoke({\"celebrity_name\": \"Elon Musk\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbafa9d",
   "metadata": {},
   "source": [
    "##### Structured Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c104ff7",
   "metadata": {},
   "source": [
    "##### DatetimeOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacbb5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.datetime import DatetimeOutputParser\n",
    "\n",
    "datetime_parser = DatetimeOutputParser()\n",
    "\n",
    "# print(datetime_parser.get_format_instructions())\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "\"\"\"Give me date of birth: {celebrity_name}. Output only the date time and nothing else.\n",
    "\\n {format_instructions}\"\"\",\n",
    "partial_variables={\"format_instructions\":datetime_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "prompt.format(celebrity_name=\"Elon Musk\")\n",
    "\n",
    "chain = prompt | google_llm | datetime_parser\n",
    "\n",
    "chain.invoke({\"celebrity_name\": \"Elon Musk\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2946c027",
   "metadata": {},
   "source": [
    "##### EnumOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef66deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.enum import EnumOutputParser\n",
    "from enum import Enum\n",
    "\n",
    "class YesNoMaybe(Enum):\n",
    "    YES = \"yes\"\n",
    "    NO = \"no\"\n",
    "    MAYBE = \"maybe\"\n",
    "\n",
    "enum_parser = EnumOutputParser(enum=YesNoMaybe)\n",
    "\n",
    "# print(enum_parser.get_format_instructions())\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Is {celebrity_name} an actor?. \\n Format instructions: {format_instructions}. \" \\\n",
    "    \"Always stick to the format instructions cases in the response\",\n",
    "   partial_variables={\"format_instructions\":enum_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "prompt.format(celebrity_name=\"Elon Musk\")\n",
    "\n",
    "chain = prompt | google_llm | enum_parser\n",
    "\n",
    "res = chain.invoke({\"celebrity_name\": \"Elon musk\"})\n",
    "\n",
    "print(\"No\") if res is YesNoMaybe.NO else None\n",
    "print(\"Yes\") if res is YesNoMaybe.YES else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab98332",
   "metadata": {},
   "source": [
    "##### RetryOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2918d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YesNoMaybe.NO\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers.enum import EnumOutputParser\n",
    "from langchain.output_parsers.retry import RetryOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel\n",
    "from enum import Enum\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "class YesNoMaybe(Enum):\n",
    "    YES = \"yes\"\n",
    "    NO = \"no\"\n",
    "    MAYBE = \"maybe\"\n",
    "\n",
    "enum_parser = EnumOutputParser(enum=YesNoMaybe)\n",
    "retry_parser = RetryOutputParser.from_llm(parser=enum_parser,llm=google_llm, max_retries=2)\n",
    "\n",
    "# print(retry_parser.get_format_instructions())\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Is {celebrity_name} an actor?. \\n Format instructions: {format_instructions}. \" \\\n",
    "    \"Always stick to the format instructions cases in the response\",\n",
    "   partial_variables={\"format_instructions\": enum_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# prompt.format(celebrity_name=\"Elon Musk\")\n",
    "\n",
    "completion_chain = prompt | google_llm | StrOutputParser()\n",
    "\n",
    "main_chain = (\n",
    "    RunnableParallel(completion=completion_chain, prompt_value=prompt) |\n",
    "    RunnableLambda(lambda x: retry_parser.parse_with_prompt(**x)) # completion=x[\"completion\"], prompt_value=x[\"prompt_value\"]\n",
    ")\n",
    "\n",
    "res = main_chain.invoke({\"celebrity_name\": \"Elon musk\"})\n",
    "\n",
    "print(res)\n",
    "\n",
    "# print(\"No\") if res is YesNoMaybe.NO else None\n",
    "# print(\"Yes\") if res is YesNoMaybe.YES else None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
