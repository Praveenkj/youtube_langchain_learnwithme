{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ec220ee",
   "metadata": {},
   "source": [
    "## RAG Basics - Practice for lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d1bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "google_llm = ChatGoogleGenerativeAI(\n",
    "    temperature=0, \n",
    "    model=\"gemini-2.0-flash\", \n",
    "    api_key=google_api_key,\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "openai_llm = ChatOpenAI(\n",
    "    temperature=0, \n",
    "    model=\"gpt-4\", \n",
    "    api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ae16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader('../docs_for_rag/coolie_large.txt')\n",
    "\n",
    "document = loader.load()\n",
    "\n",
    "for document in loader.lazy_load():\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f1fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(document)\n",
    "\n",
    "# chunks = text_splitter.split_text(document[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a011b",
   "metadata": {},
   "source": [
    "##### OpenAI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb7805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "openai_embeddings = OpenAIEmbeddings()\n",
    "\n",
    "document_texts = [document.page_content for document in documents]\n",
    "\n",
    "document_vectors = openai_embeddings.embed_documents(document_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b43efe",
   "metadata": {},
   "source": [
    "##### Google embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60adebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "google_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "document_vectors = google_embeddings.embed_documents(document_texts)\n",
    "\n",
    "print(document_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2603902d",
   "metadata": {},
   "source": [
    "##### Ollama Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4385b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "ollama_embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "document_vectors = ollama_embeddings.embed_documents(document_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c442f6",
   "metadata": {},
   "source": [
    "##### Huggingface embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b1608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "huggingface_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "document_vectors = huggingface_embeddings.embed_documents(document_texts)\n",
    "\n",
    "print(len(document_vectors[0]))\n",
    "print(document_vectors[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7770acda",
   "metadata": {},
   "source": [
    "##### FAISS - Creating vectorstore from already created embeddings vs creating from documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a309176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# vectorstore = FAISS.from_documents(documents, openai_embeddings)\n",
    "# vectorstore.similarity_search(\"who is dahaa?\")\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_embeddings(text_embeddings=list(zip(document_texts, document_vectors)), \n",
    "                                    embedding=openai_embeddings)\n",
    "vectorstore.save_local('./faiss_vectorstore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ce477b",
   "metadata": {},
   "source": [
    "##### Loading a vector store from local disk storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c935744",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vectorstore = FAISS.load_local(\n",
    "    \"./faiss_vectorstore\", \n",
    "    openai_embeddings,  # Must use same embedding model that created it\n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d202271",
   "metadata": {},
   "source": [
    "##### Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e2af2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"Answer my question only by using the below context.\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    ")\n",
    "\n",
    "vectorstore_for_chain = loaded_vectorstore.as_retriever()\n",
    "\n",
    "chain = (\n",
    "    {\"context\": vectorstore_for_chain, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template \n",
    "    | google_llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"Who is Dahaa?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
