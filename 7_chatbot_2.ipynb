{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2043abb",
   "metadata": {},
   "source": [
    "# Basic Chatbot\n",
    "### Trimming history based on last k messages\n",
    "##### Boilerplate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e377b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "google_llm = ChatGoogleGenerativeAI(\n",
    "    temperature=0,\n",
    "    model=\"gemini-2.0-flash\", \n",
    "    api_key=google_api_key,\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "openai_llm = ChatOpenAI(\n",
    "    temperature=0, \n",
    "    model=\"gpt-4\", \n",
    "    api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f55393",
   "metadata": {},
   "source": [
    "##### Just to know - Manually trimming history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b35b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful assistant. Answer all the questions very shortly and briefly'),\n",
    "    MessagesPlaceholder(\"history\"),\n",
    "    ('human',\"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt_template | google_llm | StrOutputParser()\n",
    "\n",
    "conversation = {}\n",
    "\n",
    "# {sessionid: [], sessionid: []}\n",
    "\n",
    "def chat_with_bot(payload):\n",
    "    input = payload['input']\n",
    "    session_id = payload['session_id']\n",
    "\n",
    "    if session_id not in conversation:\n",
    "        conversation[session_id] = ChatMessageHistory()\n",
    "    \n",
    "    history = conversation[session_id]\n",
    "\n",
    "    history.messages = history.messages[-2:]\n",
    "    \n",
    "    history.add_user_message(input)\n",
    "    res = chain.invoke({\"input\": input, \"history\": history.messages})\n",
    "    history.add_ai_message(res)\n",
    "    print(f\"history messages length: {len(history.messages)}\")\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "res = chat_with_bot({\"input\": \"My name is Praveen\", \"session_id\": \"user1\"})\n",
    "print(conversation, \"\\n\", res, \"\\n\")\n",
    "\n",
    "res = chat_with_bot({\"input\": \"What is google?\", \"session_id\": \"user1\"})\n",
    "print(conversation, \"\\n\", res, \"\\n\")\n",
    "\n",
    "res = chat_with_bot({\"input\": \"Where is it located?\", \"session_id\": \"user1\"})\n",
    "print(conversation, \"\\n\", res, \"\\n\")\n",
    "\n",
    "res = chat_with_bot({\"input\": \"What is my name?\", \"session_id\": \"user1\"})\n",
    "print(conversation, \"\\n\", res, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca31a3b6",
   "metadata": {},
   "source": [
    "##### Trimming history in RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e6b57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, Praveen. \n",
      "\n",
      "Donald Trump is a former U.S. President. \n",
      "\n",
      "Vladimir Putin is the President of Russia. \n",
      "\n",
      "Your name is Praveen. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful assistant. Answer all the questions very shortly and briefly'),\n",
    "    MessagesPlaceholder(\"history\"),\n",
    "    ('human',\"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt_template | google_llm | StrOutputParser()\n",
    "\n",
    "store = {}\n",
    "\n",
    "class WindowedChatMessageHistory(BaseChatMessageHistory):\n",
    "    def __init__(self, k: int = 2):\n",
    "        self._messages = deque(maxlen=k*2)\n",
    "\n",
    "    @property\n",
    "    def messages(self):\n",
    "        return list(self._messages)\n",
    "\n",
    "    def add_message(self, message: str) -> None:\n",
    "        self._messages.append(message)\n",
    "\n",
    "    def clear(self):\n",
    "        self._messages.clear()\n",
    "\n",
    "\n",
    "def get_session_history(session_id):\n",
    "    if session_id not in store:\n",
    "         store[session_id] = WindowedChatMessageHistory(k=2)\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "\n",
    "res = chain_with_history.invoke(\n",
    "    {\"input\": \"My name is Praveen.\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}}\n",
    ")\n",
    "print(res, \"\\n\")\n",
    "\n",
    "\n",
    "res = chain_with_history.invoke(\n",
    "    {\"input\": \"Who is Donald trump?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}}\n",
    ")\n",
    "print(res, \"\\n\")\n",
    "\n",
    "\n",
    "res = chain_with_history.invoke(\n",
    "    {\"input\": \"Who is Putin?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}}\n",
    ")\n",
    "print(res, \"\\n\")\n",
    "\n",
    "\n",
    "res = chain_with_history.invoke(\n",
    "    {\"input\": \"What is my name?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}}\n",
    ")\n",
    "print(res, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f0cf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hi Praveen! It's great to meet you. Python is a fantastic language. What do you enjoy doing with Python? Are you working on any interesting projects or learning anything new? I'm always interested to hear what people are doing with it.\n",
      "Summary: Praveen introduced himself and mentioned he likes Python. The AI responded, welcoming him and asking what he enjoys doing with Python and if he's working on any projects or learning anything new.\n",
      "AI: You introduced yourself as Praveen and mentioned that you like Python.\n",
      "Summary: Praveen introduced himself, mentioning he likes Python. The AI welcomed him, asked about his Python interests and projects, and then reminded him of what he had just said when he asked.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "# Where we stash session stuff\n",
    "store = {}\n",
    "\n",
    "class SummarizedHistory:\n",
    "    def __init__(self):\n",
    "        self.summary = \"The conversation is empty.\"\n",
    "        self.history = ChatMessageHistory()\n",
    "\n",
    "    def update(self, user_msg, ai_msg):\n",
    "        # Add new turn to message history\n",
    "        self.history.add_user_message(user_msg)\n",
    "        self.history.add_ai_message(ai_msg)\n",
    "\n",
    "        # Summarize old summary + new turn\n",
    "        summarize_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"Summarize the conversation so far briefly.\"),\n",
    "            (\"human\", \"Previous summary:\\n{summary}\\n\\nNew exchange:\\nUser: {user}\\nAI: {ai}\\n\\nUpdated summary:\")\n",
    "        ])\n",
    "        chain = summarize_prompt | google_llm\n",
    "        self.summary = chain.invoke({\n",
    "            \"summary\": self.summary,\n",
    "            \"user\": user_msg,\n",
    "            \"ai\": ai_msg\n",
    "        }).content\n",
    "\n",
    "# Create / get history per session\n",
    "def get_session(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = SummarizedHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Example use\n",
    "session = get_session(\"abc123\")\n",
    "\n",
    "# User says something\n",
    "user_input = \"Hey, Iâ€™m Praveen. I like Python.\"\n",
    "ai_output = google_llm.invoke(user_input).content\n",
    "session.update(user_input, ai_output)\n",
    "print(\"AI:\", ai_output)\n",
    "print(\"Summary:\", session.summary)\n",
    "\n",
    "# Next turn\n",
    "user_input = \"Remind me what I just said?\"\n",
    "ai_output = google_llm.invoke(f\"Summary so far: {session.summary}\\n\\nUser: {user_input}\").content\n",
    "session.update(user_input, ai_output)\n",
    "print(\"AI:\", ai_output)\n",
    "print(\"Summary:\", session.summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab37ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    history = store[session_id]\n",
    "    # Keep only last 10 messages\n",
    "    if len(history.messages) > 10:\n",
    "        history.messages = history.messages[-10:]\n",
    "    return history\n",
    "\n",
    "\n",
    "\n",
    "# Summarize old messages when history gets too long\n",
    "if len(history.messages) > 20:\n",
    "    old_messages = history.messages[:-10]\n",
    "    summary = llm.invoke(f\"Summarize: {old_messages}\").content\n",
    "    history.clear()\n",
    "    history.add_message(SystemMessage(content=f\"Previous conversation summary: {summary}\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
