{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "956f3b88",
   "metadata": {},
   "source": [
    "### RAG - Document Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a913373",
   "metadata": {},
   "source": [
    "##### Boilerplate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d712df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "google_llm = ChatGoogleGenerativeAI(\n",
    "    temperature=0, \n",
    "    model=\"gemini-2.0-flash\", \n",
    "    api_key=google_api_key,\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "openai_llm = ChatOpenAI(\n",
    "    temperature=0, \n",
    "    model=\"gpt-4\", \n",
    "    api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe79c36",
   "metadata": {},
   "source": [
    "##### TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa88fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader('./docs_for_rag/coolie_large.txt')\n",
    "\n",
    "text_documents = loader.load()\n",
    "\n",
    "for document in text_documents:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c64b65",
   "metadata": {},
   "source": [
    "##### CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d10872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(\n",
    "    './docs_for_rag/cars.csv'\n",
    ")\n",
    "\n",
    "csv_documents = loader.load()\n",
    "\n",
    "# print(data)\n",
    "\n",
    "for document in csv_documents:\n",
    "    print(document.page_content, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc41273",
   "metadata": {},
   "source": [
    "##### WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd2db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# loader = WebBaseLoader(\"https://www.orkut.com/\")\n",
    "# docs = loader.load()\n",
    "\n",
    "loader_multiple_pages = WebBaseLoader(\n",
    "    [\"https://www.orkut.com/\", \"https://google.com\", \"https://facebook.com\", \"https://linkedin.com\", \"https://x.com\"]\n",
    ")\n",
    "web_documents = loader_multiple_pages.lazy_load()\n",
    "\n",
    "\n",
    "for document in web_documents:\n",
    "    print(document, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacccb4b",
   "metadata": {},
   "source": [
    "##### UnstructuredLoader - Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9137d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "file_paths = [\n",
    "    './docs_for_rag/images.jpeg',\n",
    "    './docs_for_rag/nexon_brochure.pdf'\n",
    "]\n",
    "\n",
    "try:\n",
    "    loader = UnstructuredLoader(file_paths)\n",
    "    unstructured_docs = loader.load()\n",
    "    for doc in unstructured_docs:\n",
    "        if doc.page_content:\n",
    "            print(doc.page_content, \"\\n\")\n",
    "        else:\n",
    "            print(\"No text content found in the image\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd50e13",
   "metadata": {},
   "source": [
    "## Splitting\n",
    "### Length based splitting\n",
    "- Token based\n",
    "- Character based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dbad73",
   "metadata": {},
   "source": [
    "##### Token based splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe5dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(encoding_name=\"cl100k_base\", chunk_size=50, chunk_overlap=0)\n",
    "\n",
    "texts = text_splitter.split_text(text_documents[0].page_content)\n",
    "\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c476bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(encoding_name=\"cl100k_base\", chunk_size=100, chunk_overlap=30)\n",
    "\n",
    "texts = text_splitter.split_text(text_documents[0].page_content)\n",
    "\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44478a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(encoding_name=\"cl100k_base\", chunk_size=100, chunk_overlap=30)\n",
    "\n",
    "texts = text_splitter.split_text(text_documents[0].page_content)\n",
    "\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42fa276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# This works without any OpenAI API key\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tokens = encoding.encode(\"Hello world!\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Token count: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d1c7f",
   "metadata": {},
   "source": [
    "### Document based splitting\n",
    "- HTML\n",
    "- JSON\n",
    "- MD\n",
    "- Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41974231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'LangChain'}, page_content='# LangChain'),\n",
       " Document(metadata={'Header 1': 'LangChain', 'Header 2': 'What is it?'}, page_content='## What is it?\\nA framework to **build apps with LLMs** — think AI meets Lego blocks.'),\n",
       " Document(metadata={'Header 1': 'LangChain', 'Header 2': 'What is it?', 'Header 3': 'Core idea'}, page_content='### Core idea\\nCombine **prompts**, **chains**, and **agents** to make smart workflows.'),\n",
       " Document(metadata={'Header 1': 'LangChain', 'Header 2': 'What is it?', 'Header 3': 'Core idea'}, page_content='#### Example\\n`Translate: \"Hello\" → \"Bonjour\"`')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "markdown_document = \"\"\"# LangChain  \n",
    "## What is it?  \n",
    "A framework to **build apps with LLMs** — think AI meets Lego blocks.  \n",
    "\n",
    "### Core idea  \n",
    "Combine **prompts**, **chains**, and **agents** to make smart workflows.  \n",
    "\n",
    "#### Example  \n",
    "`Translate: \"Hello\" → \"Bonjour\"`  \n",
    "\"\"\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on, strip_headers=False, return_each_line=True)\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)\n",
    "md_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8822db29",
   "metadata": {},
   "source": [
    "##### Adding RecursiveCharacterTextSplitter on top of MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30e74e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'LangChain'}, page_content='# LangChain'),\n",
       " Document(metadata={'Header 1': 'LangChain', 'Header 2': 'What is it?'}, page_content='## What is it?\\nA framework to **build apps with LLMs** — think AI meets Lego blocks.'),\n",
       " Document(metadata={'Header 1': 'LangChain', 'Header 2': 'What is it?', 'Header 3': 'Core idea'}, page_content='### Core idea\\nCombine **prompts**, **chains**, and **agents** to make smart workflows.'),\n",
       " Document(metadata={'Header 1': 'LangChain', 'Header 2': 'What is it?', 'Header 3': 'Core idea'}, page_content='#### Example\\n`Translate: \"Hello\" → \"Bonjour\"`')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=30)\n",
    "\n",
    "text_documents = text_splitter.split_documents(md_header_splits)\n",
    "text_documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
